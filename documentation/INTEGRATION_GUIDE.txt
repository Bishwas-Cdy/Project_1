================================================================================
                     INTEGRATION GUIDE FOR DEVELOPERS
                 Flutter Mobile App & Django Web Backend
================================================================================

This guide shows EXACTLY how to integrate the Ranjana Script AI models
into your Flutter app and Django backend.

================================================================================
                        TABLE OF CONTENTS
================================================================================

1. Understanding the Models
2. Django Integration (Backend)
3. Flutter Integration (Mobile)
4. Model Conversion (ONNX/TFLite)
5. API Design Best Practices
6. Performance Optimization
7. Error Handling
8. Testing Your Integration

================================================================================
                    1. UNDERSTANDING THE MODELS
================================================================================

YOU HAVE 2 TRAINED MODELS:

Model 1: Classification (efficientnet_b0_best.pth)
--------------------------------------------------
- Purpose: Identify which character (1-62)
- Input: 64√ó64 grayscale image
- Output: Class ID (0-61) + confidence (0-1)
- File size: ~18 MB
- Inference time: ~50ms (CPU)

Model 2: Similarity (siamese_efficientnet_b0_best.pth)
-------------------------------------------------------
- Purpose: Compare how similar two characters are
- Input: Two 64√ó64 grayscale images
- Output: Similarity score (0-100%) + distance
- File size: ~9 MB
- Inference time: ~100ms (CPU)

Model 3: Grad-CAM (gradcam.py - NO MODEL FILE!)
------------------------------------------------
- Purpose: Show what the model is looking at
- Input: 64√ó64 grayscale image
- Output: Heatmap overlay image
- File size: Just Python code!
- Inference time: ~60ms (CPU)
- NOTE: Uses the classification model internally!

================================================================================
                  2. DJANGO INTEGRATION (BACKEND)
================================================================================

SETUP STEPS:
------------

Step 1: Install Dependencies
```bash
pip install torch torchvision pillow numpy opencv-python
```

Step 2: Copy Files to Your Django Project
```
your_django_project/
‚îú‚îÄ‚îÄ ai_models/                    ‚Üê Create this folder
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ efficientnet_b0_best.pth
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ siamese_efficientnet_b0_best.pth
‚îÇ   ‚îî‚îÄ‚îÄ src/
‚îÇ       ‚îú‚îÄ‚îÄ inference.py
‚îÇ       ‚îú‚îÄ‚îÄ gradcam.py
‚îÇ       ‚îú‚îÄ‚îÄ siamese_network.py
‚îÇ       ‚îú‚îÄ‚îÄ models.py
‚îÇ       ‚îú‚îÄ‚îÄ config.py
‚îÇ       ‚îî‚îÄ‚îÄ data_loader.py
‚îî‚îÄ‚îÄ your_app/
    ‚îî‚îÄ‚îÄ views.py               ‚Üê Add AI endpoints here
```

Step 3: Create Django Views
```python
# your_app/views.py

import sys
import os
from django.conf import settings
from django.http import JsonResponse
from django.views.decorators.csrf import csrf_exempt
import base64
from PIL import Image
import io

# Add AI models to path
sys.path.insert(0, os.path.join(settings.BASE_DIR, 'ai_models/src'))
from inference import RanjanaInference

# Initialize model once (at app startup)
MODEL_PATH = os.path.join(settings.BASE_DIR, 'ai_models/models')
classifier = None

def get_classifier():
    global classifier
    if classifier is None:
        classifier = RanjanaInference(
            'efficientnet_b0',
            checkpoint_path=os.path.join(MODEL_PATH, 'efficientnet_b0_best.pth'),
            device='cpu'  # or 'cuda' if GPU available
        )
    return classifier


@csrf_exempt
def classify_character(request):
    """POST /api/classify"""
    if request.method != 'POST':
        return JsonResponse({'error': 'POST required'}, status=405)
    
    try:
        # Get image from request
        image_data = request.FILES.get('image')
        if not image_data:
            # Try base64
            import json
            data = json.loads(request.body)
            image_base64 = data['image']
            image_bytes = base64.b64decode(image_base64)
            image = Image.open(io.BytesIO(image_bytes))
        else:
            image = Image.open(image_data)
        
        # Save temp file
        temp_path = '/tmp/django_classify.png'
        image.save(temp_path)
        
        # Classify
        model = get_classifier()
        classes, probs = model.classify(temp_path)
        
        # Clean up
        os.remove(temp_path)
        
        return JsonResponse({
            'success': True,
            'predicted_class': int(classes[0]),
            'confidence': float(probs[0]),
            'top_5_classes': [int(c) for c in classes],
            'top_5_confidences': [float(p) for p in probs]
        })
        
    except Exception as e:
        return JsonResponse({
            'success': False,
            'error': str(e)
        }, status=400)


@csrf_exempt
def compare_characters(request):
    """POST /api/similarity"""
    if request.method != 'POST':
        return JsonResponse({'error': 'POST required'}, status=405)
    
    try:
        import json
        data = json.loads(request.body)
        
        # Decode images
        image1_bytes = base64.b64decode(data['image1'])
        image2_bytes = base64.b64decode(data['image2'])
        
        image1 = Image.open(io.BytesIO(image1_bytes))
        image2 = Image.open(io.BytesIO(image2_bytes))
        
        # Save temp files
        temp1 = '/tmp/django_sim1.png'
        temp2 = '/tmp/django_sim2.png'
        image1.save(temp1)
        image2.save(temp2)
        
        # Compare
        model = get_classifier()
        similarity, distance = model.compute_similarity(temp1, temp2)
        
        # Clean up
        os.remove(temp1)
        os.remove(temp2)
        
        return JsonResponse({
            'success': True,
            'similarity_score': float(similarity),
            'distance': float(distance),
            'is_similar': distance < 0.45
        })
        
    except Exception as e:
        return JsonResponse({
            'success': False,
            'error': str(e)
        }, status=400)
```

Step 4: Add URLs
```python
# your_app/urls.py

from django.urls import path
from . import views

urlpatterns = [
    path('api/classify', views.classify_character, name='classify'),
    path('api/similarity', views.compare_characters, name='similarity'),
    # Add more endpoints as needed
]
```

Step 5: Test!
```bash
curl -X POST http://localhost:8000/api/classify \
  -F "image=@test_image.png"
```

================================================================================
                   3. FLUTTER INTEGRATION (MOBILE)
================================================================================

YOU HAVE 2 OPTIONS:

OPTION A: Call Backend API (RECOMMENDED FOR BEGINNERS)
-------------------------------------------------------

Pros:
‚úì Easy to implement
‚úì No model conversion needed
‚úì Models stay updated on server
‚úì Works immediately

Cons:
‚úó Requires internet connection
‚úó Slower (network latency)

Flutter Code:
```dart
import 'package:http/http.dart' as http;
import 'dart:convert';
import 'dart:io';

class RanjanaAI {
  final String baseUrl = 'https://yourserver.com/api';
  
  Future<Map<String, dynamic>> classifyCharacter(File imageFile) async {
    // Convert image to base64
    List<int> imageBytes = await imageFile.readAsBytes();
    String base64Image = base64Encode(imageBytes);
    
    // Make API call
    final response = await http.post(
      Uri.parse('$baseUrl/classify'),
      headers: {'Content-Type': 'application/json'},
      body: jsonEncode({'image': base64Image}),
    );
    
    if (response.statusCode == 200) {
      return jsonDecode(response.body);
    } else {
      throw Exception('Failed to classify');
    }
  }
  
  Future<Map<String, dynamic>> compareCharacters(
    File image1,
    File image2
  ) async {
    // Convert images to base64
    String base64Image1 = base64Encode(await image1.readAsBytes());
    String base64Image2 = base64Encode(await image2.readAsBytes());
    
    // Make API call
    final response = await http.post(
      Uri.parse('$baseUrl/similarity'),
      headers: {'Content-Type': 'application/json'},
      body: jsonEncode({
        'image1': base64Image1,
        'image2': base64Image2,
      }),
    );
    
    if (response.statusCode == 200) {
      return jsonDecode(response.body);
    } else {
      throw Exception('Failed to compare');
    }
  }
}

// Usage in your widget:
void analyzeCharacter() async {
  final ai = RanjanaAI();
  
  // Classify
  final result = await ai.classifyCharacter(imageFile);
  print('Predicted class: ${result['predicted_class']}');
  print('Confidence: ${result['confidence']}');
  
  // Compare
  final similarity = await ai.compareCharacters(studentImage, referenceImage);
  print('Similarity: ${similarity['similarity_score']}%');
}
```


OPTION B: On-Device Inference (ADVANCED)
-----------------------------------------

Pros:
‚úì Works offline
‚úì Faster (no network)
‚úì More private

Cons:
‚úó Requires model conversion
‚úó More complex setup
‚úó Larger app size

See Section 4 below for conversion steps!

================================================================================
              4. MODEL CONVERSION (ONNX / TensorFlow Lite)
================================================================================

FOR FLUTTER ON-DEVICE:
----------------------

Step 1: Convert PyTorch ‚Üí ONNX
```python
import torch
from src.models import get_model

# Load classification model
model = get_model('efficientnet_b0', num_classes=62, pretrained=False)
checkpoint = torch.load('models/efficientnet_b0_best.pth')
model.load_state_dict(checkpoint['model_state_dict'])
model.eval()

# Create dummy input
dummy_input = torch.randn(1, 1, 64, 64)

# Export to ONNX
torch.onnx.export(
    model,
    dummy_input,
    "efficientnet_b0.onnx",
    export_params=True,
    opset_version=11,
    input_names=['input'],
    output_names=['output'],
    dynamic_axes={
        'input': {0: 'batch_size'},
        'output': {0: 'batch_size'}
    }
)

print("‚úì Exported to efficientnet_b0.onnx")
```

Step 2: Convert ONNX ‚Üí TFLite
```bash
# Install converter
pip install onnx-tf tensorflow

# Convert ONNX to TensorFlow
onnx-tf convert -i efficientnet_b0.onnx -o efficientnet_b0_tf

# Convert TensorFlow to TFLite
python -c "
import tensorflow as tf
converter = tf.lite.TFLiteConverter.from_saved_model('efficientnet_b0_tf')
converter.optimizations = [tf.lite.Optimize.DEFAULT]
tflite_model = converter.convert()
with open('efficientnet_b0.tflite', 'wb') as f:
    f.write(tflite_model)
print('‚úì Converted to TFLite')
"
```

Step 3: Use in Flutter
```dart
// pubspec.yaml
dependencies:
  tflite_flutter: ^0.10.0

// Add model to assets
flutter:
  assets:
    - assets/efficientnet_b0.tflite

// Load and use
import 'package:tflite_flutter/tflite_flutter.dart';

class RanjanaClassifier {
  late Interpreter _interpreter;
  
  Future<void> loadModel() async {
    _interpreter = await Interpreter.fromAsset('efficientnet_b0.tflite');
    print('Model loaded!');
  }
  
  Future<int> classify(List<List<List<double>>> image) async {
    // Input: [1, 64, 64, 1] (batch, height, width, channels)
    var input = [image];
    
    // Output: [1, 62] (batch, classes)
    var output = List.filled(62, 0.0).reshape([1, 62]);
    
    // Run inference
    _interpreter.run(input, output);
    
    // Get predicted class
    int predictedClass = output[0].indexOf(output[0].reduce(max));
    return predictedClass;
  }
}
```

================================================================================
                 5. API DESIGN BEST PRACTICES
================================================================================

IMAGE FORMAT:
-------------
‚úì Accept: PNG, JPEG, base64
‚úì Resize to 64√ó64 on server
‚úì Convert to grayscale
‚úì Return clear error messages

RESPONSE FORMAT:
----------------
Always return JSON with:
```json
{
    "success": true/false,
    "data": { ... },      // if success
    "error": "message"    // if failure
}
```

RATE LIMITING:
--------------
Implement to prevent abuse:
- 100 requests per minute per user
- Use Django rate limiting middleware

CACHING:
--------
Cache reference character comparisons:
- Store embeddings for all 62 reference characters
- Compare new images against cached embeddings
- 10x faster!

================================================================================
                   6. PERFORMANCE OPTIMIZATION
================================================================================

BATCH PROCESSING:
-----------------
Process multiple images at once:
```python
# Instead of:
for img in images:
    result = model.classify(img)

# Do this:
results = model.classify_batch(images)  # 5x faster!
```

GPU ACCELERATION:
-----------------
If your server has GPU:
```python
classifier = RanjanaInference(
    'efficientnet_b0',
    checkpoint_path='...',
    device='cuda'  # ‚Üê Use GPU
)
# 10-20x faster on GPU!
```

MODEL QUANTIZATION:
-------------------
Reduce model size by 75%:
```python
import torch

# Load model
model = torch.load('efficientnet_b0_best.pth')

# Quantize
quantized_model = torch.quantization.quantize_dynamic(
    model, {torch.nn.Linear}, dtype=torch.qint8
)

# Save
torch.save(quantized_model, 'efficientnet_b0_quantized.pth')
# Size: 18 MB ‚Üí 5 MB!
```

================================================================================
                      7. ERROR HANDLING
================================================================================

COMMON ERRORS & SOLUTIONS:
--------------------------

Error: "ModuleNotFoundError: No module named 'torch'"
Solution: pip install -r requirements.txt

Error: "CUDA out of memory"
Solution: Use device='cpu' or reduce batch size

Error: "Image size mismatch"
Solution: Resize to 64√ó64 before inference
```python
from PIL import Image
img = Image.open('input.png')
img = img.resize((64, 64))
img = img.convert('L')  # Grayscale
```

Error: "Invalid image format"
Solution: Accept only PNG/JPEG, validate before processing

Error: "Model gives random predictions"
Solution: Check preprocessing - must normalize with mean=0.2611, std=0.4186

================================================================================
                   8. TESTING YOUR INTEGRATION
================================================================================

TEST CHECKLIST:
---------------

Backend (Django):
[ ] Models load successfully on startup
[ ] /api/classify returns correct class for test images
[ ] /api/similarity distinguishes similar vs different
[ ] Error handling works (invalid images, missing params)
[ ] Performance: <200ms response time
[ ] Concurrent requests don't crash server

Frontend (Flutter):
[ ] Image capture works
[ ] API calls succeed with valid images
[ ] Loading states show during inference
[ ] Results display correctly
[ ] Error messages show for failures
[ ] Works on Android and iOS

End-to-End:
[ ] Student draws character ‚Üí camera ‚Üí classify ‚Üí correct result
[ ] Compare student vs reference ‚Üí similarity score makes sense
[ ] Grad-CAM shows reasonable attention regions
[ ] App works offline (if using on-device models)
[ ] App works with slow network (if using API)

================================================================================
                      DEPLOYMENT CHECKLIST
================================================================================

Django Backend:
[ ] Set DEBUG=False in production
[ ] Use proper web server (Gunicorn + Nginx)
[ ] Set up HTTPS
[ ] Configure CORS for Flutter app
[ ] Add logging and monitoring
[ ] Set up auto-scaling if needed

Flutter App:
[ ] Test on real devices (not just emulator)
[ ] Optimize image compression before upload
[ ] Add offline support
[ ] Handle network errors gracefully
[ ] Test with poor network conditions

================================================================================
                       FINAL NOTES
================================================================================

THINGS I HAVEN'T TOLD YOU (BUT YOU SHOULD KNOW):
-------------------------------------------------

1. CLASS MAPPING: Folders are 1-62, but model outputs 0-61!
   - Folder "1" ‚Üí Model predicts 0
   - Folder "2" ‚Üí Model predicts 1
   - etc.
   - So: displayed_class = predicted_class + 1

2. PREPROCESSING IS CRITICAL:
   - MUST be 64√ó64
   - MUST be grayscale
   - MUST normalize (mean=0.2611, std=0.4186)
   - If any step is wrong, predictions will be garbage!

3. SIMILARITY THRESHOLD:
   - Distance < 0.45 = similar
   - Distance >= 0.45 = different
   - This was optimized through evaluation
   - You can adjust if needed

4. GRAD-CAM DOESN'T NEED TRAINING:
   - It's just visualization code
   - Uses the classification model
   - No separate model file needed!

5. MODEL FILES ARE LARGE:
   - 27 MB total
   - Consider CDN for distribution
   - Or bundle with app (increases app size)

6. MODELS ARE CPU-FRIENDLY:
   - Don't need GPU for inference
   - ~50-100ms per image on CPU
   - Acceptable for real-time use!

================================================================================

GOOD LUCK WITH YOUR INTEGRATION! üöÄ

If you get stuck, check:
1. documentation/TROUBLESHOOTING.txt
2. examples/example_*.py files
3. Contact Bishwas (the model developer)

================================================================================
