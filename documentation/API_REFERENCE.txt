================================================================================
                         API REFERENCE
              Complete Documentation for All Functions
================================================================================

This document provides detailed API reference for all functions in the
inference.py module - your main interface to the AI models.

================================================================================
                      TABLE OF CONTENTS
================================================================================

1. RanjanaInference Class
2. Classification Methods
3. Similarity Methods
4. Grad-CAM Methods
5. Utility Methods
6. Code Examples
7. Return Value Reference

================================================================================
                 1. RANJANA INFERENCE CLASS
================================================================================

class RanjanaInference
----------------------

Main class for all AI operations.

__init__(model_name, checkpoint_path=None, device='auto')
----------------------------------------------------------

Initialize the inference engine.

Parameters:
  - model_name (str): Model architecture name
      Options: 'efficientnet_b0', 'resnet50', 'vgg16', 'custom'
      Recommended: 'efficientnet_b0'
  
  - checkpoint_path (str, optional): Path to model weights (.pth file)
      If None, uses default path from config.yaml
      Example: 'models/efficientnet_b0_best.pth'
  
  - device (str): Computation device
      Options: 'auto', 'cuda', 'cpu'
      'auto' = Use GPU if available, else CPU

Returns:
  RanjanaInference object

Raises:
  - FileNotFoundError: If checkpoint file doesn't exist
  - RuntimeError: If model loading fails

Example:
```python
# Basic usage
model = RanjanaInference('efficientnet_b0')

# With explicit checkpoint
model = RanjanaInference(
    'efficientnet_b0',
    checkpoint_path='path/to/model.pth',
    device='cpu'
)
```

================================================================================
                  2. CLASSIFICATION METHODS
================================================================================

classify(image_path, top_k=5)
------------------------------

Classify a single character image.

Parameters:
  - image_path (str or PIL.Image): Path to image file OR PIL Image object
      Supported formats: PNG, JPEG, JPG
      Image will be automatically resized to 64×64 and converted to grayscale
  
  - top_k (int, optional): Number of top predictions to return
      Default: 5
      Range: 1-62

Returns:
  Tuple of (classes, probabilities):
    - classes (numpy.ndarray): Top K predicted class IDs (0-61)
        Shape: (top_k,)
        dtype: int64
    
    - probabilities (numpy.ndarray): Confidence scores (0-1)
        Shape: (top_k,)
        dtype: float32

Example:
```python
# Single prediction
classes, probs = model.classify('character.png')
print(f'Predicted class: {classes[0]}')
print(f'Confidence: {probs[0]:.2%}')

# Top 5 predictions
classes, probs = model.classify('character.png', top_k=5)
for i, (cls, prob) in enumerate(zip(classes, probs)):
    print(f'{i+1}. Class {cls}: {prob:.2%}')
```

Important Notes:
- Class IDs are 0-indexed (0-61), but folder names are 1-62!
- To get folder name: folder_id = class_id + 1
- Confidence scores sum to ~1.0 across all 62 classes


classify_batch(image_paths, top_k=5, batch_size=32)
----------------------------------------------------

Classify multiple images efficiently.

Parameters:
  - image_paths (list): List of image paths or PIL Image objects
  
  - top_k (int, optional): Number of top predictions per image
      Default: 5
  
  - batch_size (int, optional): Number of images to process at once
      Default: 32
      Larger = faster but more memory

Returns:
  List of tuples: [(classes, probabilities), (classes, probabilities), ...]
    Length = len(image_paths)
    Each tuple same format as classify()

Example:
```python
image_paths = ['img1.png', 'img2.png', 'img3.png']
results = model.classify_batch(image_paths)

for i, (classes, probs) in enumerate(results):
    print(f'Image {i+1}: Class {classes[0]} ({probs[0]:.2%})')
```

Performance:
- Single: ~50ms per image
- Batch: ~20ms per image (60% faster!)


================================================================================
                   3. SIMILARITY METHODS
================================================================================

compute_similarity(image1_path, image2_path)
--------------------------------------------

Compare two character images for similarity.

Parameters:
  - image1_path (str or PIL.Image): First image
  - image2_path (str or PIL.Image): Second image
      Both images will be resized to 64×64 and converted to grayscale

Returns:
  Tuple of (similarity_score, distance):
    - similarity_score (float): Percentage similarity (0-100)
        100 = identical
        0 = completely different
    
    - distance (float): Euclidean distance (0-infinity)
        0 = identical
        ~0.3 = very similar (same class)
        ~0.8 = different (different classes)
        Threshold: 0.45 for same/different

Example:
```python
# Compare two images
similarity, distance = model.compute_similarity('img1.png', 'img2.png')

print(f'Similarity: {similarity:.1f}%')
print(f'Distance: {distance:.3f}')

# Check if same class
if distance < 0.45:
    print('Same character!')
else:
    print('Different characters')
```

Use Cases:
- Verify student writing matches reference
- Find most similar reference character
- Duplicate detection
- Quality assessment


compare_batch(image_pairs, batch_size=32)
------------------------------------------

Compare multiple image pairs efficiently.

Parameters:
  - image_pairs (list): List of tuples [(img1, img2), (img1, img2), ...]
      Each element is a tuple of two image paths/PIL Images
  
  - batch_size (int, optional): Number of pairs to process at once
      Default: 32

Returns:
  List of tuples: [(similarity, distance), (similarity, distance), ...]
    Length = len(image_pairs)

Example:
```python
pairs = [
    ('student1.png', 'reference.png'),
    ('student2.png', 'reference.png'),
    ('student3.png', 'reference.png'),
]

results = model.compare_batch(pairs)

for i, (sim, dist) in enumerate(results):
    print(f'Student {i+1}: {sim:.1f}% similar')
```


================================================================================
                   4. GRAD-CAM METHODS
================================================================================

generate_gradcam(image_path, target_class=None, save_path=None)
----------------------------------------------------------------

Generate Grad-CAM visualization showing what the model focuses on.

Parameters:
  - image_path (str or PIL.Image): Input image
  
  - target_class (int, optional): Class to visualize
      If None, uses predicted class (most common use case)
      Range: 0-61
  
  - save_path (str, optional): Where to save overlay image
      If None, doesn't save (just returns)
      Example: 'outputs/gradcam_overlay.png'

Returns:
  Dictionary with:
    {
        'cam': numpy.ndarray,              # Raw heatmap (64×64)
        'overlay': PIL.Image,              # Heatmap overlaid on image
        'predicted_class': int,            # What model predicted (0-61)
        'confidence': float,               # Confidence (0-1)
        'save_path': str (if saved)        # Where overlay was saved
    }

Example:
```python
# Basic usage - visualize prediction
result = model.generate_gradcam('character.png')
print(f'Model predicted class {result["predicted_class"]}')
print(f'Confidence: {result["confidence"]:.2%}')
result['overlay'].show()  # Display overlay

# Save to file
result = model.generate_gradcam(
    'character.png',
    save_path='outputs/attention_map.png'
)

# Visualize specific class
result = model.generate_gradcam(
    'character.png',
    target_class=15  # Force visualization for class 15
)
```

Interpretation:
- RED areas = model is focusing here (important for prediction)
- BLUE areas = model ignores (not important)
- Works by computing gradients w.r.t. last convolutional layer

Use Cases:
- Debug why model made certain prediction
- Verify model looks at correct features
- Educational: show students what to focus on
- Research: understand model behavior


================================================================================
                   5. UTILITY METHODS
================================================================================

preprocess_image(image_path)
-----------------------------

Internal method - you usually don't call this directly.

Converts image to model-ready tensor.

Parameters:
  - image_path (str or PIL.Image): Input image

Returns:
  Tuple of (tensor, image):
    - tensor (torch.Tensor): Shape (1, 1, 64, 64), dtype float32
        Normalized with mean=0.2611, std=0.4186
    
    - image (PIL.Image): Resized 64×64 grayscale image

Example:
```python
tensor, image = model.preprocess_image('character.png')
print(tensor.shape)  # torch.Size([1, 1, 64, 64])
print(tensor.dtype)  # torch.float32
print(tensor.min(), tensor.max())  # Normalized values
```


get_embedding(image_path)
--------------------------

Extract 512-dimensional feature vector for an image.

Parameters:
  - image_path (str or PIL.Image): Input image

Returns:
  numpy.ndarray: Feature vector, shape (512,), dtype float32

Example:
```python
embedding = model.get_embedding('character.png')
print(embedding.shape)  # (512,)

# Use for custom similarity
import numpy as np
emb1 = model.get_embedding('img1.png')
emb2 = model.get_embedding('img2.png')
distance = np.linalg.norm(emb1 - emb2)
print(f'Distance: {distance:.3f}')
```

Use Cases:
- Cache embeddings for fast comparison
- Build search index
- Custom similarity metrics
- Clustering characters


================================================================================
                    6. CODE EXAMPLES
================================================================================

EXAMPLE 1: Simple Classification
---------------------------------
```python
from src.inference import RanjanaInference

# Initialize
model = RanjanaInference('efficientnet_b0')

# Classify
classes, probs = model.classify('test.png')
predicted_class = classes[0]
confidence = probs[0]

print(f'Prediction: Class {predicted_class}')
print(f'Confidence: {confidence:.2%}')
print(f'Folder name: {predicted_class + 1}')
```


EXAMPLE 2: Batch Processing Directory
--------------------------------------
```python
import os
from glob import glob

# Get all images
image_paths = glob('dataset/test/**/*.png', recursive=True)
print(f'Processing {len(image_paths)} images...')

# Classify in batches
results = model.classify_batch(image_paths, batch_size=64)

# Analyze results
correct = 0
for path, (classes, probs) in zip(image_paths, results):
    predicted = classes[0]
    confidence = probs[0]
    
    # Extract true class from path (e.g., "dataset/test/5/img.png" -> class 4)
    true_class = int(os.path.basename(os.path.dirname(path))) - 1
    
    if predicted == true_class:
        correct += 1

accuracy = correct / len(results)
print(f'Accuracy: {accuracy:.2%}')
```


EXAMPLE 3: Find Most Similar Reference
---------------------------------------
```python
# Student drew this
student_img = 'student_drawing.png'

# Compare against all 62 reference characters
reference_dir = 'references'
references = [f'{reference_dir}/{i}.png' for i in range(1, 63)]

# Compute similarities
pairs = [(student_img, ref) for ref in references]
results = model.compare_batch(pairs)

# Find best match
best_idx = min(range(len(results)), key=lambda i: results[i][1])
best_similarity, best_distance = results[best_idx]
best_class = best_idx

print(f'Best match: Class {best_class}')
print(f'Similarity: {best_similarity:.1f}%')
print(f'Distance: {best_distance:.3f}')
```


EXAMPLE 4: Visualize All Incorrect Predictions
-----------------------------------------------
```python
from glob import glob
import os

# Get test images
test_images = glob('dataset/test/**/*.png', recursive=True)

# Classify
results = model.classify_batch(test_images)

# Find incorrect
for path, (classes, probs) in zip(test_images, results):
    predicted = classes[0]
    confidence = probs[0]
    
    # Get true class
    true_class = int(os.path.basename(os.path.dirname(path))) - 1
    
    # If wrong, visualize why
    if predicted != true_class:
        print(f'\nWrong prediction: {path}')
        print(f'True: {true_class}, Predicted: {predicted}')
        
        # Show what model looked at
        result = model.generate_gradcam(
            path,
            save_path=f'errors/gradcam_{os.path.basename(path)}'
        )
        print(f'Saved to: {result["save_path"]}')
```


EXAMPLE 5: Real-time Classification
------------------------------------
```python
import cv2
import numpy as np
from PIL import Image

# Initialize model
model = RanjanaInference('efficientnet_b0', device='cuda')

# Open camera
cap = cv2.VideoCapture(0)

while True:
    ret, frame = cap.read()
    if not ret:
        break
    
    # Convert to PIL Image
    image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
    
    # Classify
    classes, probs = model.classify(image)
    predicted = classes[0]
    confidence = probs[0]
    
    # Display result
    cv2.putText(
        frame,
        f'Class: {predicted} ({confidence:.1%})',
        (10, 30),
        cv2.FONT_HERSHEY_SIMPLEX,
        1,
        (0, 255, 0),
        2
    )
    
    cv2.imshow('Ranjana Classification', frame)
    
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
```


================================================================================
                  7. RETURN VALUE REFERENCE
================================================================================

CLASSIFICATION RETURNS:
-----------------------
(classes, probabilities)
  classes: np.ndarray, shape (top_k,), dtype int64
    Values: 0-61 (class IDs)
  
  probabilities: np.ndarray, shape (top_k,), dtype float32
    Values: 0.0-1.0 (confidence scores)
    Sum of all 62 class probabilities = 1.0


SIMILARITY RETURNS:
-------------------
(similarity_score, distance)
  similarity_score: float
    Values: 0.0-100.0 (percentage)
    100 = identical, 0 = completely different
  
  distance: float
    Values: 0.0-infinity (Euclidean distance)
    Typical range: 0.0-2.0
    Threshold: 0.45 for same/different


GRAD-CAM RETURNS:
-----------------
{
  'cam': np.ndarray,
    Shape: (64, 64), dtype: float32
    Values: 0.0-1.0 (normalized heatmap)
  
  'overlay': PIL.Image,
    Size: (64, 64), Mode: RGB
    Red = important, Blue = unimportant
  
  'predicted_class': int,
    Values: 0-61
  
  'confidence': float,
    Values: 0.0-1.0
  
  'save_path': str (optional),
    Only present if save_path parameter was provided
}


EMBEDDING RETURNS:
------------------
np.ndarray
  Shape: (512,), dtype: float32
  Values: ~[-5.0, 5.0] (normalized features)


================================================================================
                      PERFORMANCE METRICS
================================================================================

TIMING (on CPU):
----------------
- classify(): ~50ms per image
- classify_batch(32): ~20ms per image
- compute_similarity(): ~100ms per pair
- generate_gradcam(): ~60ms per image
- get_embedding(): ~30ms per image

MEMORY USAGE:
-------------
- Model: ~70 MB RAM
- Per image: ~5 MB RAM
- Batch 32: ~200 MB RAM

GPU SPEEDUP:
------------
- classify(): 10x faster
- classify_batch(): 15x faster
- compute_similarity(): 12x faster

================================================================================

END OF API REFERENCE

For integration examples, see: documentation/INTEGRATION_GUIDE.txt
For troubleshooting, see: documentation/TROUBLESHOOTING.txt

================================================================================
